
<html xmlns = "http://www.w3.org/1999/xhtml">
<head>

 <title>Interactive Computer Music</title>

 <meta http-equiv="content-type" content="text/html; charset=utf-8" />
 <!-- midi.js package -->
 <script src="./js/MIDI/AudioDetect.js" type="text/javascript"></script>
 <script src="./js/MIDI/LoadPlugin.js" type="text/javascript"></script>
 <script src="./js/MIDI/Plugin.js" type="text/javascript"></script>
 <script src="./js/MIDI/Player.js" type="text/javascript"></script>
 <script src="./js/Window/DOMLoader.XMLHttp.js" type="text/javascript"></script>
 <script src="./js/Window/DOMLoader.script.js" type="text/javascript"></script>
 <!-- extras -->
 <script src="./inc/Base64.js" type="text/javascript"></script>
 <script src="./inc/base64binary.js" type="text/javascript"></script>
 <!--Vexflow-->
 <script src="js/vexflow.js"></script>
 <script src="bootstrap/js/bootstrap.min.js"></script>

 <script src="js/jquery-1.6.2.min.js"></script>

 <link href="style.css" rel="stylesheet" type="text/css">

 <script type="text/javascript">

 	/*
	 * Inputs: duration --- the interval at which to call the function
	 * 		   fn       --- the function to call
	 *
	 * Replaces setTimeout() with a more accurate version.
	 */
	function interval(duration, fn) {

		this.baseline = undefined;
		this.duration = duration;

		this.run = function() {
		    if (this.baseline === undefined) {
		    	this.baseline = new Date().getTime();
		    }
		    fn();
		    var end = new Date().getTime();
		    this.baseline += this.duration;
		    var nextTick = this.duration - (end - this.baseline);
		    if (nextTick < 0) {
		      nextTick = 0;
		    }
		    (function(i) {
		        i.timer = setTimeout(function() {
		        	i.run(end);
		      	}, nextTick)
		    }) (this)
	  	}

		this.end = function() {
	   		clearTimeout(this.timer);
	   		this.baseline = undefined;
	 	}

	 	// Work on this later to be able to add a "tempo" control.
	 	this.setDuration = function(dur) {
	 		this.end();
	 		this.duration = dur;
	 		this.baseline = new Date().getTime();
	 		this.run();
	 	}
	}

	 /*
	  * Draw notes on the canvas.
	  */
	function draw_state(note) {
	  // Clear the staff.
	  ctx.clear();
      var stave = new Vex.Flow.Stave(10, 0, 100);
      stave.addClef("treble").setContext(ctx).draw();
      // Convert note.
      if (note.length == 2) {
      	var new_note = new Vex.Flow.StaveNote({ keys: [note.toLowerCase().substring(0, 1) + "/" + note.substring(1, 2)], duration: "q" });
      }
	  else {
	  	var new_note = new Vex.Flow.StaveNote({ keys: [note.toLowerCase().substring(0, 2) + "/" + note.substring(2, 3)], duration: "q" });
	  }
	  var staff_notes = [];
	  // Play note.
	  if (note.length == 2) {
	    staff_notes.push(new_note);
	  }
	  else {
	  	if (note.substring(1, 2) === "#") {
	  		staff_notes.push(new_note.addAccidental(0, new Vex.Flow.Accidental("#")));
	  	}
	  	else {
	  		staff_notes.push(new_note.addAccidental(0, new Vex.Flow.Accidental("b")));
	  	}
	  }
	  // Create a voice in 1/4 for now.
	  var voice = new Vex.Flow.Voice({
	    num_beats: 1,
	    beat_value: 4,
	    resolution: Vex.Flow.RESOLUTION
	  });
	  // Add notes to voice
	  voice.addTickables(staff_notes);
	  // Format and justify the notes to 500 pixels
	  var formatter = new Vex.Flow.Formatter().joinVoices([voice]).format([voice], 500);
	  // Render voice
	  voice.draw(ctx, stave);
	}

	/*
	 * Start our machine learning.
	 */
 	function start() {
 		timer.run();
 	}

 	/*
 	 * Stop the machine learning.
 	 */
 	function stop() {
 		timer.end();
 	}

 	/*
 	 * Info object.
 	 */
	function Info(chord, note) {
		this.chord = chord;
		this.note = note;
	}

 	/*
 	 * Generic reinforcement machine learning algorithm for now.
 	 */
 	function reinforcement_learning(state, validNotes, validChords) {
 		var note = validNotes[Math.floor(Math.random() * validNotes.length)];
 		var chord = validChords[Math.floor(Math.random() * validChords.length)];
 		var chord_contents = chord["Contents"];
 		var nextNote = MIDI.keyToNote[note["Name"]];
 		var nextChord = [];
 		for (var i = 0; i < chord_contents.length; i++) {
 			nextChord.push(MIDI.keyToNote[chord_contents[i]]);
 		}
 		var next = new Info(nextChord, nextNote);
 		state.push(next);
 		return next;
 	}

 </script>

 <link href="bootstrap/css/bootstrap.min.css" rel="stylesheet" media="screen">
 <link href="bootstrap/css/bootstrap-responsive.css" rel="stylesheet">

</head>


<body background="background.jpg">


<div class="navbar-wrapper"><!-- Wrap the .navbar in .container to center it within the absolutely positioned parent. -->
<div class="container">
<div class="navbar navbar-inverse">
<div class="navbar-inner"> 
	<button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="brand" href="#">Computer Music</a> 
</div>
</div>
</div>
</div>

<div class="container">
<div class="row-fluid">
<div class="span12  offsetHalf block">
<div class="hero-unit span12">
  <br><br>
  <font color="black">

    <div id="loading">
	  <br>
	  <font size=8>Program will start soon. Data is being loaded.....</font>
	</div>

	<div id="notes">
		<canvas id="score" width="700" height="100"></canvas>
	</div>

	<div id="controls">
		<button class="btn btn-large btn-primary" type="button" onclick="start()">Start</button>
		<button class="btn btn-large btn-primary" type="button" onclick="stop()">Stop</button>
	</div>

  </font>
</div>
</div>
</div>
</div>


<script type="text/javascript">

// The current tempo (in milliseconds).
var tempo = 1000;

// Which type of machine learning are we using?
// 0 = Reinforcement Learning
// 1 = Supervised Learning
var learning_method = 0;

// Which algorithm are we using?
// 0 = Reinforcement Learning (will find reinforcement subsets later)
var algorithm = 0;

// Music notation.
var canvas = $("#score")[0];
var renderer = new Vex.Flow.Renderer(canvas, Vex.Flow.Renderer.Backends.CANVAS);
var ctx = renderer.getContext();
var stave = new Vex.Flow.Stave(10, 0, 100);

var draw_canvas = function() {
	stave.addClef("treble").setContext(ctx).draw();
};

// Reinforcement machine learning variables.
var notes = [ {"Name": "C4", "Score": 0}, 
			  {"Name": "E4", "Score": 0}, 
			  {"Name": "G4", "Score": 0}, 
			  {"Name": "C5", "Score": 0}, 
			  {"Name": "E5", "Score": 0}, 
			  {"Name": "G5", "Score": 0} ];
var chords = [ {"Name": "CMaj", "Contents": ["C4", "E4", "G4"], "Score": 0},
			   {"Name": "DMin", "Contents": ["D4", "F4", "A4"], "Score": 0},
			   {"Name": "EMin", "Contents": ["E4", "G4", "B4"], "Score": 0},
			   {"Name": "FMaj", "Contents": ["F4", "A4", "C5"], "Score": 0},
			   {"Name": "GMaj", "Contents": ["G4", "B4", "D5"], "Score": 0},
			   {"Name": "AMin", "Contents": ["A4", "C4", "E5"], "Score": 0},
			   {"Name": "BDim", "Contents": ["B4", "D5", "F5"], "Score": 0} ];
var state = [];

var timer = new interval(tempo, function() {
	var info = new Info(null, null);
	// Get the next note via reinforcement machine learning.
	if (learning_method === 0) {
		info = reinforcement_learning(state, notes, chords);
		console.log(state);
	}
	// Get the next note via supervised machine learning.
	if (learning_method === 1) {
		// Do stuff.
	}
	var note = info.note;
	var chord = info.chord; 
	MIDI.noteOn(0, note, 127, 0);
	MIDI.chordOn(1, chord, 50, 0);
	draw_state(MIDI.noteToKey[note]);
}); 

$(window).load(function() {
	$('#controls').hide();
    MIDI.loadPlugin({
		soundfontUrl: "./soundfont/",
		instruments: [ "acoustic_grand_piano", "acoustic_grand_piano" ],
		callback: function() {
			$('#loading').remove();
			$('#controls').show();
			draw_canvas();
		}
	});
});

</script>
</body>
</html>